name: Build AI Top 10 Summary

on:
  schedule:
    - cron: "5 * * * *"     # hourly at :05 UTC
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: ai-summary
  cancel-in-progress: true

jobs:
  summarize:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout gh-pages
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          fetch-depth: 0

      - name: Verify cache.json exists (+ peek)
        run: |
          if [ ! -f cache.json ]; then
            echo "::error ::cache.json not found on gh-pages"
            exit 1
          fi
          echo "First 400 chars of cache.json:"
          head -c 400 cache.json || true
          echo
          echo "Size (bytes): $(wc -c < cache.json)"

      - name: Setup Node 20
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Generate AI summary (Top 10) — deep scan cache.json
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          node - <<'NODE'
          import fs from 'node:fs/promises';

          const raw = await fs.readFile('cache.json', 'utf8').catch(()=>null);
          if (!raw) throw new Error('cache.json not readable');

          let d; try { d = JSON.parse(raw); } catch (e) { throw new Error('JSON parse failed: '+e.message); }

          // ---- Recursively collect arrays of "entry-like" objects ----
          function collectEntries(x, depth=0, out=[]) {
            if (depth > 5 || x == null) return out;
            if (Array.isArray(x)) {
              // Is this an array of likely entries? (has title/link/date-ish)
              const looksLikeEntries = x.some(v => v && typeof v === 'object' && (
                'title' in v || 'link' in v || 'url' in v || 'published' in v || 'date' in v || 'isoDate' in v
              ));
              if (looksLikeEntries) out.push(...x);
              // Still scan inside (some arrays contain nested arrays/objects)
              for (const v of x) collectEntries(v, depth+1, out);
            } else if (typeof x === 'object') {
              for (const k of Object.keys(x)) collectEntries(x[k], depth+1, out);
            }
            return out;
          }

          const entries = collectEntries(d);
          console.log('[ai-summary] discovered entries:', entries.length);

          if (!entries.length) {
            const msg = '**Summary of Fantasy Impact (Top 10)**\n\nNo recent items found in cache.json.\n';
            const generatedAt = new Date().toISOString();
            await fs.writeFile('top10.txt', msg + `\nUpdated: ${generatedAt}\n`, 'utf8');
            await fs.writeFile('top10.json', JSON.stringify({ generatedAt, items: [], summary: msg.trim() }, null, 2), 'utf8');
            console.log('[ai-summary] Wrote placeholder files (no entries).');
            process.exit(0);
          }

          const items = entries.map(it => ({
            title: it?.title ?? 'Untitled',
            link: it?.link || it?.url || '',
            source: it?.feedTitle || it?.source || '',
            date: it?.published || it?.publishedAt || it?.date || it?.isoDate || it?.createdAt || it?.updated || null
          }))
          // Filter out junk/no-title rows
          .filter(it => it.title || it.link)
          // Deduplicate identical titles+links
          .reduce((acc, cur) => {
            const key = (cur.title||'') + '|' + (cur.link||'');
            if (!acc._seen.has(key)) { acc._seen.add(key); acc.list.push(cur); }
            return acc;
          }, {_seen:new Set(), list:[]}).list
          // Sort newest first and take top 10
          .sort((a,b) => new Date(b.date||0) - new Date(a.date||0))
          .slice(0, 10);

          console.log('[ai-summary] first titles:', items.slice(0,3).map(i=>i.title));

          const prompt = [
            "Summarize the fantasy football impact of these recent articles.",
            "Group bullets by themes: Injuries, Transactions, Depth/Usage, Waivers, Start/Sit.",
            "Be concise and actionable. End with 3 takeaways.",
            "Articles:",
            ...items.map((it, i) => `(${i+1}) ${it.title} — ${it.link}`)
          ].join("\n");

          if (!process.env.OPENAI_API_KEY) throw new Error('Missing OPENAI_API_KEY secret.');

          const resp = await fetch("https://api.openai.com/v1/responses", {
            method: "POST",
            headers: {
              "content-type": "application/json",
              "authorization": `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
              model: "gpt-4.1-mini",
              input: prompt,
              temperature: 0.4
            })
          });

          const bodyText = await resp.text();
          if (!resp.ok) {
            console.error('[ai-summary] OpenAI error', resp.status, resp.statusText);
            console.error(bodyText.slice(0, 1000));
            throw new Error('OpenAI request failed');
          }

          let data; try { data = JSON.parse(bodyText); } catch (e) { throw new Error('OpenAI JSON parse failed'); }
          const text = (data.output_text || "No summary returned.").trim();
          const generatedAt = new Date().toISOString();

          await fs.writeFile('top10.txt', text + `\n\nUpdated: ${generatedAt}\n`, 'utf8');
          await fs.writeFile('top10.json', JSON.stringify({ generatedAt, items, summary: text }, null, 2), 'utf8');
          console.log('[ai-summary] Wrote top10.txt and top10.json');
          NODE

      - name: Commit & push
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add top10.txt top10.json || true
          git diff --cached --quiet || git commit -m "chore: update AI Top 10 summary [skip ci]"
          git push origin gh-pages
